## 빅데이터

### Hadoop MapReduce 플랫폼 특성

확장성이 있고 문제 발생시 이를 잘 대처해줌. 하지만 맵과 리듀스 작업을 진행하는데 이 사이의 중간 결과물을 디스크에 쓰게 하여 늦은 처리 속도. 이것으로 인해 반복적인 작업에 좋지 않음. (대부분의 기계학습 작업) 하둡의 초기 목적이 딥러닝 등이 아니고 대규모 분산 처리에 대해 빠르게 처리하려는 목적이었음. 때문에 딥러닝 등에 대해 성능이 안나오게 되는 결과를 보이는 것. 

초기 진입 장벽에 대해 파이썬 같은 스크립트 언어가 유리하다고 할 것이다. 하둡 초기 버전은 스크립트 기반 언어가 지원되지 않았음. 이것이 불편했다. 이러한 단점을 극복하기 위해 나온것이 스파크. 

### 스파크 목적 및 장점

디스크가 아닌 메모리를 사용하여 처리 시간을 단축 하였다. 반복적인 워킹 데이터 셋을 메모리에 올려 반복 작업에 대해 많이 극복함. 기계학습 작업에 대해 유리하게 되었다. 인터랙티브한 셀을 제공 함으로써 작업에 유리. 

다양한 API를 지원한다. 하둡은 Map/Reduce API만 지원했다. 하둡 시스템의 장점인 확장성, 안정성, 데이터 전송 최소회등 장점은 그대로 가져갔다. 

#### 스파크 특징

다양한 언어의 API지원. 스칼라 자바 파이썬 R등 지원. 기존 하둡은 자바만 지원했음. 데이터 저장소도 다양하게 지원. HDFS, local file system, S3, databases 등... 다양한 언어의 인터랙티브 쉘을 지원. 스파크 쉘 등

#### 스파크 구조

스파크 코어라는 것이 있고 그 위에 다양한 응용이 올라감. 우리는 스파크 코어를 중점으로 다룰 것. 

스파크 코어는 핵심 API를 지원한다. 다양한 분산 서버에 어떻게 작업을 분배시킬수 있는 핵심 API들임. 확장성 및 안정성을 보장한다. 스파크 코어에서 정의 된 API를 통해 다양한 API를 지원하기도 한다. 

코어 아래에 자리잡은 것들은 분산자원의 OS라고 이해하면 좋다. 스케줄러, 얀, 메모스. 어떤 자원으로 보내고 운용할 것인지 등을 처리하기 때문이다. 

#### 실습

실습에서는 movies.csv, tags.csv 파일을 이용하게 될 것이다. 

첫번째로 할 것은, Databricks 커뮤니티에 업로드를 선택해 각 파일을 업로드 한다.  경로가 /FileStore/shared_uploads/email 형식으로 작성되니 확인. display(dbutils.fs.ls("path")) 명령어로 확인. 

하고나서 스파크쉘에서 데이터 로드를 해본다

```scala
val movies = sc.textFIle("path")
println(movies.count())
println(movies.first())
println(movies.take(2))
```

#### 스파크의 세부 구조

스파크는 기본적으로 분산 처리 환경. 서버를 확장하며 데이터를 처리 하도록 만들었다. 복잡한 분산 시스템에서의 추상화를 굉장히 잘해준다. 병렬 분산 처리에 대해 처리 잘해줌. 작업을 잘 분배하는 등의 일을 한다. 분산 처리에 대한 복잡한 것들을 처리해줌. 사용자는 코딩만 수행하면 되도록 함. 클러스터 매니저가 자원을 잘 분배. 

##### 드라이버 프로그램

마스터라고 해서 프로세스라고 이해하면 된다. 작업을 관리해줌. 작업의 시작점. 스칼라 인터프리터 자체라고 생각하면 된다. 스파크 컨텍스트라는 객체를 생성하여 외부의 워커노드와 작업..?

스파크 컨텍스트라는 sc. 작업을 보내주고 작성한 것을 분산환경에서 실행하는 것. 코어 대표적 객체. 스파크 환경에서 실행되는 객체라고 생각하면. 클라스터와 연결. 하나의 jvm(드라이버)에 하나의 sc객체 들어감 중간에 들어가는 하나의 객체. 실행하면 자동으로 생성되고 변수명은 sc이다. 그다음은 워커노드. 스파크 작업을 수행하는 분산 기기. 하나의 호스트 기기에 하나 워커 노드. 프로세스로서 동작하고 있음. 스파크 컨텍스트가 작업을 필요한 것을 워커에다가 말해서 익스큐터 하고 작업을 하도록 도와주고. 워커노드는 작업을 받아서 익스큐터에 넣어줌. 익스큐터는 하나의 노드에 동시에 실행되는 Jvm,. 여러개 가능. 

클러스터 매니저랑 워커노드가 연결되어있음. 드라이버. 인터프리터라고 보면 되는데 이 안에 스파크 컨텍스트 오브젝트가 존재. 이 오브젝트가 클러스터 매니저 요청. 작업 분배는 클러스터 매니저가 함. 